[
  {
    "title": "GPT-4 Technical Report",
    "url": "https://arxiv.org/abs/2303.08774",
    "published": "2023-03-15",
    "year": 2023,
    "organization": "OpenAI",
    "category": "foundation_models",
    "source": "arxiv"
  },
  {
    "title": "Language Models are Few-Shot Learners",
    "url": "https://arxiv.org/abs/2005.14165",
    "published": "2020-05-28",
    "year": 2020,
    "organization": "OpenAI",
    "category": "foundation_models",
    "source": "arxiv"
  },
  {
    "title": "LLaMA: Open and Efficient Foundation Language Models",
    "url": "https://arxiv.org/abs/2302.13971",
    "published": "2023-02-27",
    "year": 2023,
    "organization": "Meta AI",
    "category": "foundation_models",
    "source": "arxiv"
  },
  {
    "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
    "url": "https://arxiv.org/abs/2307.09288",
    "published": "2023-07-18",
    "year": 2023,
    "organization": "Meta AI",
    "category": "foundation_models",
    "source": "arxiv"
  },
  {
    "title": "PaLM: Scaling Language Modeling with Pathways",
    "url": "https://arxiv.org/abs/2204.02311",
    "published": "2022-04-05",
    "year": 2022,
    "organization": "Google Research",
    "category": "foundation_models",
    "source": "arxiv"
  },
  {
    "title": "PaLM 2 Technical Report",
    "url": "https://arxiv.org/abs/2305.10403",
    "published": "2023-05-17",
    "year": 2023,
    "organization": "Google Research",
    "category": "foundation_models",
    "source": "arxiv"
  },
  {
    "title": "Gemini: A Family of Highly Capable Multimodal Models",
    "url": "https://arxiv.org/abs/2312.11805",
    "published": "2023-12-19",
    "year": 2023,
    "organization": "Google DeepMind",
    "category": "foundation_models",
    "source": "arxiv"
  },
  {
    "title": "Large Language Models Encode Clinical Knowledge",
    "url": "https://arxiv.org/abs/2212.13138",
    "published": "2022-12-26",
    "year": 2022,
    "organization": "Google Research",
    "category": "clinical_llm",
    "source": "arxiv"
  },
  {
    "title": "Towards Expert-Level Medical Question Answering with Large Language Models",
    "url": "https://arxiv.org/abs/2305.09617",
    "published": "2023-05-16",
    "year": 2023,
    "organization": "Google Research",
    "category": "clinical_llm",
    "source": "arxiv"
  },
  {
    "title": "Capabilities of GPT-4 on Medical Challenge Problems",
    "url": "https://arxiv.org/abs/2303.13375",
    "published": "2023-03-20",
    "year": 2023,
    "organization": "Microsoft Research",
    "category": "clinical_llm",
    "source": "arxiv"
  },
  {
    "title": "BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining",
    "url": "https://academic.oup.com/bib/article/23/6/bbac409/6713511",
    "published": "2022-09-19",
    "year": 2022,
    "organization": "Microsoft Research",
    "category": "foundation_models",
    "source": "pubmed",
    "code_url": "https://github.com/microsoft/BioGPT"
  },
  {
    "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
    "url": "https://arxiv.org/abs/1901.08746",
    "published": "2019-01-25",
    "year": 2019,
    "organization": "Korea University",
    "category": "foundation_models",
    "source": "arxiv",
    "code_url": "https://github.com/dmis-lab/biobert"
  },
  {
    "title": "PubMedBERT: Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing",
    "url": "https://arxiv.org/abs/2007.15779",
    "published": "2020-07-31",
    "year": 2020,
    "organization": "Microsoft Research",
    "category": "foundation_models",
    "source": "arxiv",
    "code_url": "https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract"
  },
  {
    "title": "SciBERT: A Pretrained Language Model for Scientific Text",
    "url": "https://arxiv.org/abs/1903.10676",
    "published": "2019-03-26",
    "year": 2019,
    "organization": "Allen Institute for AI",
    "category": "foundation_models",
    "source": "arxiv",
    "code_url": "https://github.com/allenai/scibert"
  },
  {
    "title": "Clinical-Longformer and Clinical-BigBird: Transformers for long clinical sequences",
    "url": "https://arxiv.org/abs/2201.11838",
    "published": "2022-01-27",
    "year": 2022,
    "organization": "Allen Institute for AI",
    "category": "clinical_documentation",
    "source": "arxiv",
    "code_url": "https://huggingface.co/yikuan8/Clinical-Longformer"
  },
  {
    "title": "ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission",
    "url": "https://arxiv.org/abs/1904.05342",
    "published": "2019-04-10",
    "year": 2019,
    "organization": "MIT",
    "category": "clinical_documentation",
    "source": "arxiv",
    "code_url": "https://github.com/kexinhuang12345/clinicalBERT"
  },
  {
    "title": "Towards Building Open-source Language Models for Medicine",
    "url": "https://arxiv.org/abs/2304.14454",
    "published": "2023-04-27",
    "year": 2023,
    "organization": "Shanghai Jiao Tong University",
    "category": "foundation_models",
    "source": "arxiv"
  },
  {
    "title": "ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge",
    "url": "https://arxiv.org/abs/2303.14070",
    "published": "2023-03-24",
    "year": 2023,
    "organization": "UC San Diego",
    "category": "clinical_llm",
    "source": "arxiv",
    "code_url": "https://github.com/Kent0n-Li/ChatDoctor"
  },
  {
    "title": "MEDITRON-70B: Scaling Medical Pretraining for Large Language Models",
    "url": "https://arxiv.org/abs/2311.16079",
    "published": "2023-11-27",
    "year": 2023,
    "organization": "EPFL",
    "category": "foundation_models",
    "source": "arxiv",
    "code_url": "https://github.com/epfLLM/meditron"
  },
  {
    "title": "Segment Anything in Medical Images",
    "url": "https://arxiv.org/abs/2304.12306",
    "published": "2023-04-24",
    "year": 2023,
    "organization": "University of Toronto",
    "category": "medical_imaging",
    "source": "arxiv",
    "code_url": "https://github.com/bowang-lab/MedSAM"
  },
  {
    "title": "SAM-Med3D",
    "url": "https://arxiv.org/abs/2310.15161",
    "published": "2023-10-23",
    "year": 2023,
    "organization": "United Imaging Intelligence",
    "category": "medical_imaging",
    "source": "arxiv",
    "code_url": "https://github.com/uni-medical/SAM-Med3D"
  },
  {
    "title": "Medical Image Segmentation with Diffusion Probabilistic Model",
    "url": "https://arxiv.org/abs/2211.00611",
    "published": "2022-11-01",
    "year": 2022,
    "organization": "Stanford University",
    "category": "medical_imaging",
    "source": "arxiv",
    "code_url": "https://github.com/KidsWithTokens/MedSegDiff"
  },
  {
    "title": "UniverSeg: Universal Medical Image Segmentation",
    "url": "https://arxiv.org/abs/2304.06131",
    "published": "2023-04-12",
    "year": 2023,
    "organization": "MIT",
    "category": "medical_imaging",
    "source": "arxiv",
    "code_url": "https://github.com/JJGO/UniverSeg"
  },
  {
    "title": "An open-source framework for deep learning in healthcare",
    "url": "https://arxiv.org/abs/2211.02701",
    "published": "2022-11-05",
    "year": 2022,
    "organization": "NVIDIA",
    "category": "medical_imaging",
    "source": "arxiv",
    "code_url": "https://github.com/Project-MONAI/MONAI"
  },
  {
    "title": "Training a Large Language-and-Vision Assistant for Biomedicine in One Day",
    "url": "https://arxiv.org/abs/2306.00890",
    "published": "2023-06-01",
    "year": 2023,
    "organization": "Microsoft Research",
    "category": "multimodal",
    "source": "arxiv",
    "code_url": "https://github.com/microsoft/LLaVA-Med"
  },
  {
    "title": "A multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs",
    "url": "https://arxiv.org/abs/2303.00915",
    "published": "2023-03-02",
    "year": 2023,
    "organization": "Microsoft Research",
    "category": "multimodal",
    "source": "arxiv",
    "code_url": "https://github.com/microsoft/BiomedCLIP"
  },
  {
    "title": "Flamingo: a Visual Language Model for Few-Shot Learning",
    "url": "https://arxiv.org/abs/2204.14198",
    "published": "2022-04-29",
    "year": 2022,
    "organization": "DeepMind",
    "category": "multimodal",
    "source": "arxiv"
  },
  {
    "title": "CLIP: Learning Transferable Visual Models From Natural Language Supervision",
    "url": "https://arxiv.org/abs/2103.00020",
    "published": "2021-02-26",
    "year": 2021,
    "organization": "OpenAI",
    "category": "multimodal",
    "source": "arxiv",
    "code_url": "https://github.com/openai/CLIP"
  },
  {
    "title": "Highly accurate protein structure prediction with AlphaFold",
    "url": "https://www.nature.com/articles/s41586-021-03819-2",
    "published": "2021-07-15",
    "year": 2021,
    "organization": "DeepMind",
    "category": "drug_discovery",
    "source": "nature",
    "code_url": "https://github.com/deepmind/alphafold"
  },
  {
    "title": "Accurate structure prediction of biomolecular interactions with AlphaFold 3",
    "url": "https://www.nature.com/articles/s41586-024-07487-w",
    "published": "2024-05-08",
    "year": 2024,
    "organization": "Google DeepMind",
    "category": "drug_discovery",
    "source": "nature"
  },
  {
    "title": "Accurate prediction of protein structures and interactions using a three-track neural network",
    "url": "https://www.science.org/doi/10.1126/science.abj8754",
    "published": "2021-07-15",
    "year": 2021,
    "organization": "University of Washington",
    "category": "drug_discovery",
    "source": "science",
    "code_url": "https://github.com/RosettaCommons/RoseTTAFold"
  },
  {
    "title": "Diffusion Steps, Twists, and Turns for Molecular Docking",
    "url": "https://arxiv.org/abs/2210.01776",
    "published": "2022-10-04",
    "year": 2022,
    "organization": "MIT",
    "category": "drug_discovery",
    "source": "arxiv",
    "code_url": "https://github.com/gcorso/DiffDock"
  },
  {
    "title": "Molecular Contrastive Learning of Representations via Graph Neural Networks",
    "url": "https://arxiv.org/abs/2102.10056",
    "published": "2021-02-19",
    "year": 2021,
    "organization": "Stanford University",
    "category": "drug_discovery",
    "source": "arxiv",
    "code_url": "https://github.com/snap-stanford/MoCL"
  },
  {
    "title": "Language models of protein sequences at the scale of evolution enable accurate structure prediction",
    "url": "https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1",
    "published": "2022-07-21",
    "year": 2022,
    "organization": "Meta AI",
    "category": "genomics",
    "source": "biorxiv",
    "code_url": "https://github.com/facebookresearch/esm"
  },
  {
    "title": "Evolutionary-scale prediction of atomic-level protein structure with a language model",
    "url": "https://www.science.org/doi/10.1126/science.ade2574",
    "published": "2023-03-16",
    "year": 2023,
    "organization": "Meta AI",
    "category": "genomics",
    "source": "science",
    "code_url": "https://github.com/facebookresearch/esm"
  },
  {
    "title": "Toward Building a Foundation Model for Single-Cell Multi-omics Using Generative AI",
    "url": "https://www.nature.com/articles/s41592-024-02201-0",
    "published": "2024-02-08",
    "year": 2024,
    "organization": "University of Toronto",
    "category": "genomics",
    "source": "nature",
    "code_url": "https://github.com/bowang-lab/scGPT"
  },
  {
    "title": "Transfer learning enables predictions in network biology",
    "url": "https://www.nature.com/articles/s41586-023-06139-9",
    "published": "2023-05-31",
    "year": 2023,
    "organization": "Broad Institute",
    "category": "genomics",
    "source": "nature",
    "code_url": "https://huggingface.co/ctheodoris/Geneformer"
  },
  {
    "title": "DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome",
    "url": "https://academic.oup.com/bioinformatics/article/37/15/2112/6128680",
    "published": "2021-02-06",
    "year": 2021,
    "organization": "Georgia Tech",
    "category": "genomics",
    "source": "pubmed",
    "code_url": "https://github.com/jerryji1993/DNABERT"
  },
  {
    "title": "Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics",
    "url": "https://www.biorxiv.org/content/10.1101/2023.01.11.523679v1",
    "published": "2023-01-11",
    "year": 2023,
    "organization": "InstaDeep",
    "category": "genomics",
    "source": "biorxiv",
    "code_url": "https://github.com/instadeepai/nucleotide-transformer"
  },
  {
    "title": "Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning",
    "url": "https://www.nature.com/articles/s41551-022-00936-9",
    "published": "2022-09-15",
    "year": 2022,
    "organization": "Stanford University",
    "category": "radiology",
    "source": "nature",
    "code_url": "https://github.com/rajpurkarlab/CheXzero"
  },
  {
    "title": "Visual Question Answering in the Medical Domain",
    "url": "https://arxiv.org/abs/2009.13081",
    "published": "2020-09-28",
    "year": 2020,
    "organization": "Montreal University",
    "category": "radiology",
    "source": "arxiv"
  },
  {
    "title": "RoentGen: Vision-Language Foundation Model for Chest X-ray Generation",
    "url": "https://arxiv.org/abs/2211.12737",
    "published": "2022-11-23",
    "year": 2022,
    "organization": "Stanford University",
    "category": "radiology",
    "source": "arxiv"
  },
  {
    "title": "Artificial Intelligence in Mental Health and the Biases of Language Based Models",
    "url": "https://arxiv.org/abs/2008.11103",
    "published": "2020-08-25",
    "year": 2020,
    "organization": "University of Washington",
    "category": "mental_health",
    "source": "arxiv"
  },
  {
    "title": "The effectiveness of using a chatbot to provide mental health support: A systematic review",
    "url": "https://formative.jmir.org/2017/1/e7",
    "published": "2017-06-06",
    "year": 2017,
    "organization": "Stanford University",
    "category": "mental_health",
    "source": "pubmed"
  },
  {
    "title": "Language models can predict public health trends",
    "url": "https://arxiv.org/abs/2301.08986",
    "published": "2023-01-21",
    "year": 2023,
    "organization": "Harvard T.H. Chan School",
    "category": "public_health",
    "source": "arxiv"
  },
  {
    "title": "Deep learning for viral mutation prediction",
    "url": "https://www.nature.com/articles/s41586-023-06617-0",
    "published": "2023-10-11",
    "year": 2023,
    "organization": "Harvard Medical School",
    "category": "public_health",
    "source": "nature"
  },
  {
    "title": "Synthetic Data Generation for Healthcare",
    "url": "https://arxiv.org/abs/2304.03243",
    "published": "2023-04-06",
    "year": 2023,
    "organization": "MIT",
    "category": "synthetic_data",
    "source": "arxiv"
  },
  {
    "title": "Diffusion Models for Medical Image Synthesis",
    "url": "https://arxiv.org/abs/2304.01593",
    "published": "2023-04-04",
    "year": 2023,
    "organization": "Stanford University",
    "category": "synthetic_data",
    "source": "arxiv"
  },
  {
    "title": "Ethical and social risks of harm from Language Models",
    "url": "https://arxiv.org/abs/2112.04359",
    "published": "2021-12-08",
    "year": 2021,
    "organization": "DeepMind",
    "category": "ethics_fairness",
    "source": "arxiv"
  },
  {
    "title": "On the Opportunities and Risks of Foundation Models",
    "url": "https://arxiv.org/abs/2108.07258",
    "published": "2021-08-16",
    "year": 2021,
    "organization": "Stanford University",
    "category": "ethics_fairness",
    "source": "arxiv"
  }
]