[
  {
    "source": "pubmed",
    "title": "Evaluation of GPT-4o for multilingual translation of radiology reports across imaging modalities.",
    "abstract": "",
    "published": "2025-08-31",
    "journal": "European journal of radiology",
    "pmid": "",
    "paper_id": "3d26b707e15b",
    "category": "medical_imaging"
  },
  {
    "source": "pubmed",
    "title": "Assessing LLM-generated vs. expert-created clinical anatomy MCQs: a student perception-based comparative study in medical education.",
    "abstract": "Large language models (LLMs) such as ChatGPT and Gemini are increasingly used to generate educational content in medical education, including multiple-choice questions (MCQs), but their effectiveness compared to expert-written questions remains underexplored, particularly in anatomy. We conducted a cross-sectional, mixed-methods study involving Year 2-4 medical students at Qatar University, where participants completed and evaluated three anonymized MCQ sets-authored by ChatGPT, Google-Gemini, and a clinical anatomist-across 17 quality criteria. Descriptive and chi-square analyses were performed, and optional feedback was reviewed thematically. Among 48 participants, most rated the three MCQ sources as equally effective, although ChatGPT was more often preferred for helping students identify and confront their knowledge gaps through challenging distractors and diagnostic insight, while expert-written questions were rated highest for deeper analytical thinking. A significant variation in preferences was observed across sources (&#x3c7;&#xb2; (64) = 688.79, <i>p</i> &lt; .001). Qualitative feedback emphasized the need for better difficulty calibration and clearer distractors in some AI-generated items. Overall, LLM-generated anatomy MCQs can closely match expert-authored ones in learner-perceived value and may support deeper engagement, but expert review remains critical to ensure clarity and alignment with curricular goals. A hybrid AI-human workflow may provide a promising path for scalable, high-quality assessment design in medical education.",
    "published": "2025-08-30",
    "journal": "Medical education online",
    "pmid": "",
    "paper_id": "ae55a0350f3b",
    "category": "patient_care"
  },
  {
    "source": "pubmed",
    "title": "Clinical decision support for pharmacologic management of treatment-resistant depression with augmented large language models.",
    "abstract": "",
    "published": "2025-08-30",
    "journal": "Journal of mood and anxiety disorders",
    "pmid": "",
    "paper_id": "cf6bdad1c26d",
    "category": "clinical_apps"
  },
  {
    "source": "arxiv",
    "title": "DriveQA: Passing the Driving Knowledge Test",
    "abstract": "If a Large Language Model (LLM) were to take a driving knowledge test today, would it pass? Beyond standard spatial and visual question-answering (QA) tasks on current autonomous driving benchmarks, driving knowledge tests require a complete understanding of all traffic rules, signage, and right-of-way principles. To pass this test, human drivers must discern various edge cases that rarely appear in real-world datasets. In this work, we present DriveQA, an extensive open-source text and vision-based benchmark that exhaustively covers traffic regulations and scenarios. Through our experiments using DriveQA, we show that (1) state-of-the-art LLMs and Multimodal LLMs (MLLMs) perform well on basic traffic rules but exhibit significant weaknesses in numerical reasoning and complex right-of-way scenarios, traffic sign variations, and spatial layouts, (2) fine-tuning on DriveQA improves accuracy across multiple categories, particularly in regulatory sign recognition and intersection decision-making, (3) controlled variations in DriveQA-V provide insights into model sensitivity to environmental factors such as lighting, perspective, distance, and weather conditions, and (4) pretraining on DriveQA enhances downstream driving task performance, leading to improved results on real-world datasets such as nuScenes and BDD, while also demonstrating that models can internalize text and synthetic traffic knowledge to generalize effectively across downstream QA tasks.",
    "authors": [
      "Maolin Wei",
      "Wanzhou Liu",
      "Eshed Ohn-Bar"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21824v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21824v1.pdf",
    "categories": [
      "cs.CV"
    ],
    "paper_id": "954681c76210",
    "category": "ethics"
  },
  {
    "source": "arxiv",
    "title": "A new characterization of the holographic entropy cone",
    "abstract": "Entanglement entropies computed using the holographic Ryu-Takayanagi formula are known to obey an infinite set of linear inequalities, which define the so-called RT entropy cone. The general structure of this cone, or equivalently the set of all valid inequalities, is unknown. It is also unknown whether those same inequalities are also obeyed by entropies computed using the covariant Hubeny-Rangamani-Takayanagi formula, although significant evidence has accumulated that they are. Using Markov states, we develop a test of this conjecture in a heretofore unexplored regime. The test reduces to checking that a given inequality obeys a certain majorization property, which is easy to evaluate. We find that the RT inequalities pass this test and, surprisingly, \\emph{only} RT inequalities do so. Our results not only provide strong new evidence that the HRT and RT cones coincide, but also offer a completely new characterization of that cone.",
    "authors": [
      "Guglielmo Grimaldi",
      "Matthew Headrick",
      "Veronika E. Hubeny"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21823v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21823v1.pdf",
    "categories": [
      "hep-th"
    ],
    "paper_id": "1c8adf02a54c",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "Scattering for the non-radial inhomogeneous Hartree equation with a   potential",
    "abstract": "In this work, we consider the focusing generalized inhomogeneous Hartree equation with potential \\[ i u_t + \\Delta u - V(x)u + \\left(I_{\\gamma} * |x|^{-b}|u|^{p}\\right)|x|^{-b}|u|^{p-2}u = 0, \\] where $0&lt;\\gamma&lt;3$ and $0&lt;b&lt;\\frac{1+\\gamma}{2}$. We prove scattering in the intercritical case for nonradial initial data, under a mass-potential condition that generalizes the usual mass-energy threshold. The main new points compared to previous works are the inhomogeneous weight $|x|^{-b}$ and the presence of a potential $V$, which lead us to study the perturbed operator $-\\Delta + V$.   Our proof follows the general strategy of Murphy, but we need to adapt several steps to deal with the weight and the potential. We use Tao's scattering criterion together with localized Morawetz estimates in this setting. As a preliminary step, we establish global well-posedness for small data, which, in the presence of $V$, requires careful analysis using appropriate admissible Strichartz pairs.",
    "authors": [
      "Carlos M. Guzmán",
      "Suerlan Silva",
      "Gabriel Peçanha"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21822v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21822v1.pdf",
    "categories": [
      "math.AP"
    ],
    "paper_id": "5e3e373640cb",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "An Introduction to Gravitational Wave Theory",
    "abstract": "Introduction to the theoretical foundations of gravitational waves: from general relativity to detection and binary system waveforms. Lecture notes prepared for the MaNiTou summer school on gravitational waves. Draft chapter for the CNRS contemporary Encyclopaedia Sciences to be published by ISTE.",
    "authors": [
      "Simone Speziale",
      "Danièle A. Steer"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21817v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21817v1.pdf",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-th"
    ],
    "paper_id": "5cfe17cd16ff",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "Achieving Hilbert-Schmidt Independence Under Rényi Differential   Privacy for Fair and Private Data Generation",
    "abstract": "As privacy regulations such as the GDPR and HIPAA and responsibility frameworks for artificial intelligence such as the AI Act gain traction, the ethical and responsible use of real-world data faces increasing constraints. Synthetic data generation has emerged as a promising solution to risk-aware data sharing and model development, particularly for tabular datasets that are foundational to sensitive domains such as healthcare. To address both privacy and fairness concerns in this setting, we propose FLIP (Fair Latent Intervention under Privacy guarantees), a transformer-based variational autoencoder augmented with latent diffusion to generate heterogeneous tabular data. Unlike the typical setup in fairness-aware data generation, we assume a task-agnostic setup, not reliant on a fixed, defined downstream task, thus offering broader applicability. To ensure privacy, FLIP employs R\\'enyi differential privacy (RDP) constraints during training and addresses fairness in the input space with RDP-compatible balanced sampling that accounts for group-specific noise levels across multiple sampling rates. In the latent space, we promote fairness by aligning neuron activation patterns across protected groups using Centered Kernel Alignment (CKA), a similarity measure extending the Hilbert-Schmidt Independence Criterion (HSIC). This alignment encourages statistical independence between latent representations and the protected feature. Empirical results demonstrate that FLIP effectively provides significant fairness improvements for task-agnostic fairness and across diverse downstream tasks under differential privacy constraints.",
    "authors": [
      "Tobias Hyrup",
      "Emmanouil Panagiotou",
      "Arjun Roy",
      "Arthur Zimek",
      "Eirini Ntoutsi",
      "Peter Schneider-Kamp"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21815v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21815v1.pdf",
    "categories": [
      "cs.LG"
    ],
    "paper_id": "a28e96e305de",
    "category": "ethics"
  },
  {
    "source": "arxiv",
    "title": "Unitary induced channels and Tsirelson's problem",
    "abstract": "Motivated by a recent progress concerning quantum commuting and quantum tensor models of composed systems we investigate a notion of (generalized) unitary induced quantum channel. Using properties of Brown algebras we provide an equivalent characterization of discussed families in both tensor and commuting paradigms. In particular, we provide an equivalent formulation of Tsirelson's conjecture (Connes' embedding problem) in terms of considered paradigms based on protocols which do not require measurements performed on infinite-dimensional subsystems. As a result we show that there is a difference between quantum commuting and quantum tensor models for generalized unitary induced channels.",
    "authors": [
      "Michał Banacki",
      "Paweł Horodecki"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21808v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21808v1.pdf",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP",
      "81R15"
    ],
    "paper_id": "790a82c472c3",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large   Language Models",
    "abstract": "The growing scale of Large Language Models (LLMs) has necessitated the development of parameter-efficient fine-tuning techniques. Low-Rank Adaptation (LoRA) has emerged as a promising approach, reducing the number of trainable parameters by applying low-rank updates to pretrained weights. While standard LoRA learns both update factors directly, several recent variants first initialize those matrices via an SVD of the pretrained weights -- an operation that can be expensive on large models and yields singular vectors that are not always easy to interpret. In this work, we extract an orthonormal basis from the pretrained weight matrix using QR decomposition with column pivoting, and then express the LoRA update as a linear combination of these basis vectors -- training only the scalar coefficients, which imposes clear structure on adaptation and drastically reduces parameter count. Experiments across GLUE tasks show that QR-LoRA matches or exceeds the performance of full fine-tuning, standard LoRA, and SVD-LoRA (LoRA with update matrices initialized via singular value decomposition) with as few as 601 parameters -- a reduction of over 1000x compared to full fine-tuning and 77x fewer than typical LoRA setups.",
    "authors": [
      "Jessica Liang",
      "Anirudh Bharadwaj"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21810v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21810v1.pdf",
    "categories": [
      "cs.LG"
    ],
    "paper_id": "e75309a888be",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "Automated Clinical Problem Detection from SOAP Notes using a   Collaborative Multi-Agent LLM Architecture",
    "abstract": "Accurate interpretation of clinical narratives is critical for patient care, but the complexity of these notes makes automation challenging. While Large Language Models (LLMs) show promise, single-model approaches can lack the robustness required for high-stakes clinical tasks. We introduce a collaborative multi-agent system (MAS) that models a clinical consultation team to address this gap. The system is tasked with identifying clinical problems by analyzing only the Subjective (S) and Objective (O) sections of SOAP notes, simulating the diagnostic reasoning process of synthesizing raw data into an assessment. A Manager agent orchestrates a dynamically assigned team of specialist agents who engage in a hierarchical, iterative debate to reach a consensus. We evaluated our MAS against a single-agent baseline on a curated dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration demonstrated consistently improved performance in identifying congestive heart failure, acute kidney injury, and sepsis. Qualitative analysis of the agent debates reveals that this structure effectively surfaces and weighs conflicting evidence, though it can occasionally be susceptible to groupthink. By modeling a clinical team's reasoning process, our system offers a promising path toward more accurate, robust, and interpretable clinical decision support tools.",
    "authors": [
      "Yeawon Lee",
      "Xiaoyang Wang",
      "Christopher C. Yang"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21803v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21803v1.pdf",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "paper_id": "c8151816e9c4",
    "category": "clinical_apps"
  },
  {
    "source": "arxiv",
    "title": "DMGIN: How Multimodal LLMs Enhance Large Recommendation Models for   Lifelong User Post-click Behaviors",
    "abstract": "Modeling user interest based on lifelong user behavior sequences is crucial for enhancing Click-Through Rate (CTR) prediction. However, long post-click behavior sequences themselves pose severe performance issues: the sheer volume of data leads to high computational costs and inefficiencies in model training and inference. Traditional methods address this by introducing two-stage approaches, but this compromises model effectiveness due to incomplete utilization of the full sequence context. More importantly, integrating multimodal embeddings into existing large recommendation models (LRM) presents significant challenges: These embeddings often exacerbate computational burdens and mismatch with LRM architectures. To address these issues and enhance the model's efficiency and accuracy, we introduce Deep Multimodal Group Interest Network (DMGIN). Given the observation that user post-click behavior sequences contain a large number of repeated items with varying behaviors and timestamps, DMGIN employs Multimodal LLMs(MLLM) for grouping to reorganize complete lifelong post-click behavior sequences more effectively, with almost no additional computational overhead, as opposed to directly introducing multimodal embeddings. To mitigate the potential information loss from grouping, we have implemented two key strategies. First, we analyze behaviors within each group using both interest statistics and intra-group transformers to capture group traits. Second, apply inter-group transformers to temporally ordered groups to capture the evolution of user group interests. Our extensive experiments on both industrial and public datasets confirm the effectiveness and efficiency of DMGIN. The A/B test in our LBS advertising system shows that DMGIN improves CTR by 4.7% and Revenue per Mile by 2.3%.",
    "authors": [
      "Zhuoxing Wei",
      "Qingchen Xie",
      "Qi Liu"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21801v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21801v1.pdf",
    "categories": [
      "cs.IR"
    ],
    "paper_id": "ea044814eb4c",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection   Models with a Text Memory Bank",
    "abstract": "Anomaly detection, which aims to identify anomalies deviating from normal patterns, is challenging due to the limited amount of normal data available. Unlike most existing unified methods that rely on carefully designed image feature extractors and memory banks to capture logical relationships between objects, we introduce a text memory bank to enhance the detection of logical anomalies. Specifically, we propose a Three-Memory framework for Unified structural and logical Anomaly Detection (TMUAD). First, we build a class-level text memory bank for logical anomaly detection by the proposed logic-aware text extractor, which can capture rich logical descriptions of objects from input images. Second, we construct an object-level image memory bank that preserves complete object contours by extracting features from segmented objects. Third, we employ visual encoders to extract patch-level image features for constructing a patch-level memory bank for structural anomaly detection. These three complementary memory banks are used to retrieve and compare normal images that are most similar to the query image, compute anomaly scores at multiple levels, and fuse them into a final anomaly score. By unifying structural and logical anomaly detection through collaborative memory banks, TMUAD achieves state-of-the-art performance across seven publicly available datasets involving industrial and medical domains. The model and code are available at https://github.com/SIA-IDE/TMUAD.",
    "authors": [
      "Jiawei Liu",
      "Jiahe Hou",
      "Wei Wang",
      "Jinsong Du",
      "Yang Cong",
      "Huijie Fan"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21795v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21795v1.pdf",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "paper_id": "85e4a860a42e",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "MoE-Health: A Mixture of Experts Framework for Robust Multimodal   Healthcare Prediction",
    "abstract": "Healthcare systems generate diverse multimodal data, including Electronic Health Records (EHR), clinical notes, and medical images. Effectively leveraging this data for clinical prediction is challenging, particularly as real-world samples often present with varied or incomplete modalities. Existing approaches typically require complete modality data or rely on manual selection strategies, limiting their applicability in real-world clinical settings where data availability varies across patients and institutions. To address these limitations, we propose MoE-Health, a novel Mixture of Experts framework designed for robust multimodal fusion in healthcare prediction. MoE-Health architecture is specifically developed to handle samples with differing modalities and improve performance on critical clinical tasks. By leveraging specialized expert networks and a dynamic gating mechanism, our approach dynamically selects and combines relevant experts based on available data modalities, enabling flexible adaptation to varying data availability scenarios. We evaluate MoE-Health on the MIMIC-IV dataset across three critical clinical prediction tasks: in-hospital mortality prediction, long length of stay, and hospital readmission prediction. Experimental results demonstrate that MoE-Health achieves superior performance compared to existing multimodal fusion methods while maintaining robustness across different modality availability patterns. The framework effectively integrates multimodal information, offering improved predictive performance and robustness in handling heterogeneous and incomplete healthcare data, making it particularly suitable for deployment in diverse healthcare environments with heterogeneous data availability.",
    "authors": [
      "Xiaoyang Wang",
      "Christopher C. Yang"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21793v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21793v1.pdf",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "paper_id": "2595e4ff7d67",
    "category": "documentation"
  },
  {
    "source": "arxiv",
    "title": "Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing   Fine Web for Problematic Content Search and Retrieval",
    "abstract": "Large language models (LLMs) rely heavily on web-scale datasets like Common Crawl, which provides over 80\\% of training data for some modern models. However, the indiscriminate nature of web crawling raises challenges in data quality, safety, and ethics. Despite the critical importance of training data quality, prior research on harmful content has been limited to small samples due to computational constraints. This project presents a framework for indexing and analyzing LLM training datasets using an ElasticSearch-based pipeline. We apply it to SwissAI's FineWeb-2 corpus (1.5TB, four languages), achieving fast query performance--most searches in milliseconds, all under 2 seconds. Our work demonstrates real-time dataset analysis, offering practical tools for safer, more accountable AI systems.",
    "authors": [
      "Inés Altemir Marinas",
      "Anastasiia Kucherenko",
      "Andrei Kucharavy"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21788v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21788v1.pdf",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "paper_id": "40b34d4afb8d",
    "category": "ethics"
  },
  {
    "source": "arxiv",
    "title": "The properties of a Leontief production technology for Health System   Modeling: the Thanzi la Onse model for Malawi",
    "abstract": "As health system modeling (HSM) advances to include more complete descriptions of the production of healthcare, it is important to establish a robust conceptual characterisation of the production process. For the Thanzi La Onse model in Malawi we have incorporated an approach to production that is based on a form of Leontief technology -- fixed input proportions. At first sight, this form of technology appears restrictive relative to the general conception of a production function employed in economics. In particular, the Leontief technology is associated with constant returns to scale, and level sets that are piecewise linear, both of which are highly restrictive properties. In this article we demonstrate that once incorporated into an all disease, agent-based model these properties are no longer present and the Leontief framework becomes a rich structure for describing healthcare production, and hence for examining the returns to health systems investments.",
    "authors": [
      "Martin Chalkley",
      "Sakshi Mohan",
      "Margherita Molaro",
      "Bingling She",
      "Wiktoria Tafesse"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21699v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21699v1.pdf",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "paper_id": "c8e3e55019ea",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "A Survey on Current Trends and Recent Advances in Text Anonymization",
    "abstract": "The proliferation of textual data containing sensitive personal information across various domains requires robust anonymization techniques to protect privacy and comply with regulations, while preserving data usability for diverse and crucial downstream tasks. This survey provides a comprehensive overview of current trends and recent advances in text anonymization techniques. We begin by discussing foundational approaches, primarily centered on Named Entity Recognition, before examining the transformative impact of Large Language Models, detailing their dual role as sophisticated anonymizers and potent de-anonymization threats. The survey further explores domain-specific challenges and tailored solutions in critical sectors such as healthcare, law, finance, and education. We investigate advanced methodologies incorporating formal privacy models and risk-aware frameworks, and address the specialized subfield of authorship anonymization. Additionally, we review evaluation frameworks, comprehensive metrics, benchmarks, and practical toolkits for real-world deployment of anonymization solutions. This review consolidates current knowledge, identifies emerging trends and persistent challenges, including the evolving privacy-utility trade-off, the need to address quasi-identifiers, and the implications of LLM capabilities, and aims to guide future research directions for both academics and practitioners in this field.",
    "authors": [
      "Tobias Deußer",
      "Lorenz Sparrenberg",
      "Armin Berger",
      "Max Hahnbück",
      "Christian Bauckhage",
      "Rafet Sifa"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21587v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21587v1.pdf",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "paper_id": "efc7bbffcc60",
    "category": "ethics"
  },
  {
    "source": "arxiv",
    "title": "HealthProcessAI: A Technical Framework and Proof-of-Concept for   LLM-Enhanced Healthcare Process Mining",
    "abstract": "Process mining has emerged as a powerful analytical technique for understanding complex healthcare workflows. However, its application faces significant barriers, including technical complexity, a lack of standardized approaches, and limited access to practical training resources. We introduce HealthProcessAI, a GenAI framework designed to simplify process mining applications in healthcare and epidemiology by providing a comprehensive wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address unfamiliarity and improve accessibility, the framework integrates multiple Large Language Models (LLMs) for automated process map interpretation and report generation, helping translate technical analyses into outputs that diverse users can readily understand. We validated the framework using sepsis progression data as a proof-of-concept example and compared the outputs of five state-of-the-art LLM models through the OpenRouter platform. To test its functionality, the framework successfully processed sepsis data across four proof-of-concept scenarios, demonstrating robust technical performance and its capability to generate reports through automated LLM analysis. LLM evaluation using five independent LLMs as automated evaluators revealed distinct model strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By integrating multiple Large Language Models (LLMs) for automated interpretation and report generation, the framework addresses widespread unfamiliarity with process mining outputs, making them more accessible to clinicians, data scientists, and researchers. This structured analytics and AI-driven interpretation combination represents a novel methodological advance in translating complex process mining results into potentially actionable insights for healthcare applications.",
    "authors": [
      "Eduardo Illueca-Fernandez",
      "Kaile Chen",
      "Fernando Seoane",
      "Farhad Abtahi"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21540v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21540v1.pdf",
    "categories": [
      "cs.AI"
    ],
    "paper_id": "dffa443f461f",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "Fundamentals of Data-Driven Approaches to Acoustic Signal Detection,   Filtering, and Transformation",
    "abstract": "In recent decades, the field of signal processing has rapidly evolved due to diverse application demands, leading to a rich array of scientific questions and research areas. The forms of signals, their formation mechanisms, and the information extraction methods vary by application, resulting in diverse signal processing techniques. Common techniques can be categorized into three types: transformation, detection, and filtering. Signal transformation converts signals from their original domain to a more suitable target domain for analysis; signal detection aims to identify the existence of relevant information within a signal and its specific time and location; and signal filtering focuses on extracting or separating source signals of interest from observed signals. In acoustic signal processing, techniques include sound source localization, sound event detection, voiceprint extraction and recognition, noise reduction, and source separation, with applications in speech communication, voice interaction, smart healthcare, and industrial diagnostics. Recently, the advancement of deep learning technologies has shifted methodologies in acoustic signal processing from knowledge-driven to data-driven approaches, leading to significant research outcomes. This paper aims to systematically summarize the principles and methods of data-driven acoustic signal processing, providing a comprehensive understanding framework for academic exploration and practical applications.",
    "authors": [
      "Chao Pan"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21470v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21470v1.pdf",
    "categories": [
      "eess.AS"
    ],
    "paper_id": "da0fedc3b938",
    "category": "patient_care"
  },
  {
    "source": "arxiv",
    "title": "A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor   Segmentation in Diagnostic and Therapeutic MRI",
    "abstract": "Automated segmentation of Pancreatic Ductal Adenocarcinoma (PDAC) from MRI is critical for clinical workflows but is hindered by poor tumor-tissue contrast and a scarcity of annotated data. This paper details our submission to the PANTHER challenge, addressing both diagnostic T1-weighted (Task 1) and therapeutic T2-weighted (Task 2) segmentation. Our approach is built upon the nnU-Net framework and leverages a deep, multi-stage cascaded pre-training strategy, starting from a general anatomical foundation model and sequentially fine-tuning on CT pancreatic lesion datasets and the target MRI modalities. Through extensive five-fold cross-validation, we systematically evaluated data augmentation schemes and training schedules. Our analysis revealed a critical trade-off, where aggressive data augmentation produced the highest volumetric accuracy, while default augmentations yielded superior boundary precision (achieving a state-of-the-art MASD of 5.46 mm and HD95 of 17.33 mm for Task 1). For our final submission, we exploited this finding by constructing custom, heterogeneous ensembles of specialist models, essentially creating a mix of experts. This metric-aware ensembling strategy proved highly effective, achieving a top cross-validation Tumor Dice score of 0.661 for Task 1 and 0.523 for Task 2. Our work presents a robust methodology for developing specialized, high-performance models in the context of limited data and complex medical imaging tasks (Team MIC-DKFZ).",
    "authors": [
      "Omer Faruk Durugol",
      "Maximilian Rokuss",
      "Yannick Kirchhoff",
      "Klaus H. Maier-Hein"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21775v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21775v1.pdf",
    "categories": [
      "cs.CV"
    ],
    "paper_id": "f364c1b36ff9",
    "category": "medical_imaging"
  },
  {
    "source": "arxiv",
    "title": "Sequential Fair Allocation With Replenishments: A Little Envy Goes An   Exponentially Long Way",
    "abstract": "We study the trade-off between envy and inefficiency in repeated resource allocation settings with stochastic replenishments, motivated by real-world systems such as food banks and medical supply chains. Specifically, we consider a model in which a decision-maker faced with stochastic demand and resource donations must trade off between an equitable and efficient allocation of resources over an infinite horizon. The decision-maker has access to storage with fixed capacity $M$, and incurs efficiency losses when storage is empty (stockouts) or full (overflows). We provide a nearly tight (up to constant factors) characterization of achievable envy-inefficiency pairs. Namely, we introduce a class of Bang-Bang control policies whose inefficiency exhibits a sharp phase transition, dropping from $\\Theta(1/M)$ when $\\Delta = 0$ to $e^{-\\Omega(\\Delta M)}$ when $\\Delta &gt; 0$, where $\\Delta$ is used to denote the target envy of the policy. We complement this with matching lower bounds, demonstrating that the trade-off is driven by supply, as opposed to demand uncertainty. Our results demonstrate that envy-inefficiency trade-offs not only persist in settings with dynamic replenishment, but are shaped by the decision-maker's available capacity, and are therefore qualitatively different compared to previously studied settings with fixed supply.",
    "authors": [
      "Chido Onyeze",
      "Sean R. Sinclair",
      "Chamsi Hssaine",
      "Siddhartha Banerjee"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21753v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21753v1.pdf",
    "categories": [
      "math.OC",
      "cs.GT",
      "math.PR"
    ],
    "paper_id": "2e3f3f26d836",
    "category": "foundation"
  },
  {
    "source": "arxiv",
    "title": "Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL,   Rogue Software and Auto-SNL",
    "abstract": "The LCLS-II Free Electron Laser (FEL) will generate X-ray pulses for beamline experiments at rates of up to 1~MHz, with detectors producing data throughputs exceeding 1 TB/s. Managing such massive data streams presents significant challenges, as transmission and storage infrastructures become prohibitively expensive. Machine learning (ML) offers a promising solution for real-time data reduction, but conventional implementations introduce excessive latency, making them unsuitable for high-speed experimental environments. To address these challenges, SLAC developed the SLAC Neural Network Library (SNL), a specialized framework designed to deploy real-time ML inference models on Field-Programmable Gate Arrays (FPGA). SNL's key feature is the ability to dynamically update model weights without requiring FPGA resynthesis, enhancing flexibility for adaptive learning applications. To further enhance usability and accessibility, we introduce Auto-SNL, a Python extension that streamlines the process of converting Python-based neural network models into SNL-compatible high-level synthesis code. This paper presents a benchmark comparison against hls4ml, the current state-of-the-art tool, across multiple neural network architectures, fixed-point precisions, and synthesis configurations targeting a Xilinx ZCU102 FPGA. The results showed that SNL achieves competitive or superior latency in most tested architectures, while in some cases also offering FPGA resource savings. This adaptation demonstrates SNL's versatility, opening new opportunities for researchers and academics in fields such as high-energy physics, medical imaging, robotics, and many more.",
    "authors": [
      "Hamza Ezzaoui Rahali",
      "Abhilasha Dave",
      "Larry Ruckman",
      "Mohammad Mehdi Rahimifar",
      "Audrey C. Therrien",
      "James J. Russel",
      "Ryan T. Herbst"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21739v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21739v1.pdf",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "paper_id": "e970183a6d4c",
    "category": "medical_imaging"
  },
  {
    "source": "arxiv",
    "title": "Developer Insights into Designing AI-Based Computer Perception Tools",
    "abstract": "Artificial intelligence (AI)-based computer perception (CP) technologies use mobile sensors to collect behavioral and physiological data for clinical decision-making. These tools can reshape how clinical knowledge is generated and interpreted. However, effective integration of these tools into clinical workflows depends on how developers balance clinical utility with user acceptability and trustworthiness. Our study presents findings from 20 in-depth interviews with developers of AI-based CP tools. Interviews were transcribed and inductive, thematic analysis was performed to identify 4 key design priorities: 1) to account for context and ensure explainability for both patients and clinicians; 2) align tools with existing clinical workflows; 3) appropriately customize to relevant stakeholders for usability and acceptability; and 4) push the boundaries of innovation while aligning with established paradigms. Our findings highlight that developers view themselves as not merely technical architects but also ethical stewards, designing tools that are both acceptable by users and epistemically responsible (prioritizing objectivity and pushing clinical knowledge forward). We offer the following suggestions to help achieve this balance: documenting how design choices around customization are made, defining limits for customization choices, transparently conveying information about outputs, and investing in user training. Achieving these goals will require interdisciplinary collaboration between developers, clinicians, and ethicists.",
    "authors": [
      "Maya Guhan",
      "Meghan E. Hurley",
      "Eric A. Storch",
      "John Herrington",
      "Casey Zampella",
      "Julia Parish-Morris",
      "Gabriel Lázaro-Muñoz",
      "Kristin Kostick-Quenet"
    ],
    "published": "2025-08-29",
    "updated": "2025-08-29",
    "arxiv_id": "2508.21733v1",
    "pdf_url": "https://arxiv.org/pdf/2508.21733v1.pdf",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "paper_id": "94fcffe9c0ae",
    "category": "clinical_apps"
  },
  {
    "source": "pubmed",
    "title": "Visual art and representation in cardiology: Past, present, and future.",
    "abstract": "Cardiovascular diseases (CVD) have been the leading causes of morbidity and mortality for over three decades, highlighting the necessity of integrating creative methods with traditional and innovative approaches for patient care, education, and prevention. Historically, artistic representations have played a crucial role in shaping our understanding of the anatomy, physiology, and pathologies of the human heart and cardiovascular system. Creative expressions, including visual arts, are linked to improved overall well-being for individuals of all ages. This review explores the evolution of visual arts in cardiovascular medicine over time, the understanding, diagnosis, and communication of cardiovascular disease and health through major domains of visual arts - education (medical illustrations, interactive anatomic models), symbolism (healing), advocacy (heart disease awareness, cardiac-focused exhibitions, interactive murals or art installations) and innovation (3D modeling, digital art, generative art, advanced medical visualization and imaging). We also reviewed the latest advancements in incorporating visual art into personalized cardiac care, the role of portraits in recognizing underrepresented groups, and future applications of visual representations and concepts through artificial intelligence aimed at enhancing cardiovascular care, medical education, and cardiac research.",
    "published": "2025-08-29",
    "journal": "American heart journal",
    "pmid": "",
    "paper_id": "b36fd7cac3c7",
    "category": "patient_care"
  },
  {
    "source": "pubmed",
    "title": "Comparison of ChatGPT-3.5 and GPT-4 as potential tools in artificial intelligence-assisted clinical practice in renal and liver transplantation.",
    "abstract": "",
    "published": "2025-08-29",
    "journal": "World journal of transplantation",
    "pmid": "",
    "paper_id": "45048647fb92",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Design of an intelligent AI-based multi-layer optimization framework for grid-tied solar PV-fuel cell hybrid energy systems.",
    "abstract": "The method proposed in this work focused on a multi-level AI framework capable of enhancing the performance of a grid-tied solar PV-fuel cell hybrid energy system. RL-ENN stands for Reinforcement Learning-Driven Evolutionary Neural Network, while T-STFREP is a generalized acronym for Transformer-Based Spatiotemporal Forecasting. FL-DEO stands for Federated Learning-Based Distributed Optimization. GNN-HSCO is Graph Neural Networks Power Router. Q-GAN-ESO is Quantum-Inspired Generative Adversarial Networks. RL-ENN helps minimize Net Present Cost (NPC) and Cost of Energy (COE) in real-time with adaptive energy dispatch strategies; T-STFREP verifies accuracy based on forecasting transformer temporal sequence; FL-DEO allows for optimization in decentralized manner with privacy; and finally, GNN-HSCO considers hybrid networking as energy graphs to diminish transmission losses whereas finally Q-GAN-ESO looks at synthetic degradation scenarios to allow for optimal management of energy storage. The application under consideration was simulated in MATLAB/Simulink and Python with TensorFlow, with a 30-year evaluation of meteorological data. The proposed model has decreased NPC by 27.5 %, COE by 18.2 %, and battery life by 30.2 %. The results validate its capability when compared against traditional methods such as Genetic Algorithms and Particle Swarm Optimization. With this, we now have a scalable and real-time energy-efficient solution for future smart grid systems.&#x2022;<b>Integrated Intelligence Stack</b>: Combines RL-ENN, T-STFREP, FL-DEO, GNN-HSCO, and Q-GAN-ESO into a unified architecture for real-time control, forecasting, decentralized optimization, network routing, and synthetic scenario generation.&#x2022;<b>Real-Time, Scalable, and Privacy-Preserving</b>: Enables adaptive energy dispatch, federated optimization without compromising data privacy, and graph-based power routing, making it suitable for large-scale, smart grid deployments.&#x2022;<b>Proven Long-Term Performance</b>: Achieved significant improvements over traditional methods (GA, PSO) with <b>27.5 % lower NPC, 18.2 % reduction in COE</b>, and <b>30.2 % increase in battery life</b>, validated using 30 years of meteorological data.",
    "published": "2025-08-27",
    "journal": "MethodsX",
    "pmid": "",
    "paper_id": "3fe898e0523e",
    "category": "genomics"
  },
  {
    "source": "pubmed",
    "title": "Analyses of different prescriptions for health using artificial intelligence: a critical approach based on the international guidelines of health institutions.",
    "abstract": "",
    "published": "2025-08-27",
    "journal": "Health information science and systems",
    "pmid": "",
    "paper_id": "de3ef7e6f8c4",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Depression intervention using AI chatbots with social cues: a randomized trial of effectiveness.",
    "abstract": "",
    "published": "2025-08-12",
    "journal": "Journal of affective disorders",
    "pmid": "",
    "paper_id": "e31fa5ee1b85",
    "category": "patient_care"
  },
  {
    "source": "pubmed",
    "title": "Evaluation of a retrieval-augmented generation system using a Japanese Institutional Nuclear Medicine Manual and large language model-automated scoring.",
    "abstract": "Recent advances in large language models (LLMs) enable domain-specific question answering using external knowledge. However, addressing information that is not included in training data remains a challenge, particularly in nuclear medicine, where examination protocols are frequently updated and vary across institutions. In this study, we developed a retrieval-augmented generation (RAG) system using 40 internal manuals from a single Japanese hospital, each corresponding to a different examination in nuclear medicine. These institution-specific documents were segmented and indexed using a hybrid retrieval strategy combining dense vector search (text-embedding-3-small) and sparse keyword search (BM25). GPT-3.5 and GPT-4o were used with the OpenAI application programming interface (API) for response generation. The quality of the generated answers was assessed using a four-point Likert scale by three certified radiological technologists, of which one held an additional certification in nuclear medicine and another held an additional certification in medical physics. Automated evaluation was conducted using RAGAS metrics, including factual correctness and context recall. The GPT-4o model combined with hybrid retrieval achieved the highest performance, as per expert evaluations. Although traditional string-based metrics such as ROUGE and the Levenshtein distance poorly align with human ratings, RAGAS provided consistent rankings across system configurations, despite showing only a modest correlation with manual scores. These findings demonstrate that integrating examination-specific institutional manuals into RAG frameworks can effectively support domain-specific question answering in nuclear medicine. Moreover, LLM-based evaluation methods such as RAGAS may serve as practical tools to complement expert reviews in developing healthcare-oriented artificial intelligence systems.",
    "published": "2025-08-11",
    "journal": "Radiological physics and technology",
    "pmid": "",
    "paper_id": "2cd75c0f51b4",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Patterns, advances, and gaps in using ChatGPT and similar technologies in nursing education: A PAGER scoping review.",
    "abstract": "",
    "published": "2025-08-07",
    "journal": "Nurse education today",
    "pmid": "",
    "paper_id": "3b4aa1ba5844",
    "category": "patient_care"
  },
  {
    "source": "pubmed",
    "title": "ChatGPT based method for obtaining repeatable and quantitative colorimetric measurements.",
    "abstract": "The rise of artificial intelligence (AI) applications in the modern industry has been shown to boost productivity in many sectors such as manufacturing, mining, finance, marketing, pharmacy, textiles, and a few more industries. AI is a neural network system that is wired to learn by interacting with humans and by repetition of tasks. A sub-category of AI common to many ordinary citizens is the Chat Generative Pre-training Transformer (ChatGPT) a program of OpenAI Global, LLC., that generates human-like dialogue and responses from the user input. &#x2022; ChatGPT can be used to determine colorimetric values for the assessment of environmental pollutants such as congo red (CR) and coomassie brilliant blue (CBB) and prove its ability for consistent reproducibility. &#x2022; Several color models have been developed such as CIE Lab, RGB, and Xyz to quantify colors. &#x2022; We used ChatGPT, in conjunction with Color Grab which is an Android app, to quantitatively determine the RGB values of the pollutant solutions, and investigated the color difference &#x394;E, as well as the hue and chroma that facilitates the color absorption of the pollutants. &#x2022; The results from ChatGPT and Color Grab were confirmed with the well-established ultra-violet visible (UV-Vis) spectrophotometer.",
    "published": "2025-08-06",
    "journal": "MethodsX",
    "pmid": "",
    "paper_id": "a2ce05ff2214",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Artificial intelligence and robotic surgery in clinical medicine: progress, challenges, and future directions.",
    "abstract": "Technological innovations in medicine are increasingly expected to replicate the diagnostic, decision-making, and procedural skills of experienced physicians. This review explores the evolution, current status, and limitations of artificial intelligence (AI) and robotic surgery in clinical practice. Radiology and pathology have led the way in digital transformation, enabling AI applications through standardized datasets and electronic health records. However, limitations such as algorithmic opacity, legal-ethical uncertainties, and fragmented digital infrastructures continue to hinder broader implementation. In robotic surgery, soft tissue procedures have not yet demonstrated significant advantages over conventional laparoscopy in terms of cost or operative efficiency. Orthopedic applications, particularly in arthroplasty, are promising but still lack long-term validation. Importantly, for any technology to create true value in healthcare, its benefits must clearly outweigh its costs. As healthcare systems face mounting pressure from aging populations and rising procedural demand, particularly for cholecystectomy, prostatectomy, and arthroplasty, the development of efficient and scalable technologies becomes inevitable. While neither AI nor robotic surgery has yet fulfilled its transformative promise, historical trends suggest that innovation will persist toward overcoming these barriers.",
    "published": "2025-08-06",
    "journal": "Future science OA",
    "pmid": "",
    "paper_id": "9c762cf424e5",
    "category": "medical_imaging"
  },
  {
    "source": "pubmed",
    "title": "Enhancing AI for citation screening in literature reviews: Improving accuracy with ensemble models.",
    "abstract": "",
    "published": "2025-08-02",
    "journal": "International journal of medical informatics",
    "pmid": "",
    "paper_id": "98e99e4f651e",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Zero-Shot Extraction of Seizure Outcomes from Clinical Notes Using Generative Pretrained Transformers.",
    "abstract": "",
    "published": "2025-07-31",
    "journal": "Journal of healthcare informatics research",
    "pmid": "",
    "paper_id": "17868c4c2434",
    "category": "documentation"
  },
  {
    "source": "pubmed",
    "title": "Missing data imputation of climate time series: A review.",
    "abstract": "Missing data in climate time series is a significant problem because it complicates the monitoring and prediction of climatic phenomena. The primary objective of this research document is to describe the most relevant imputation methods for missing data in the climate context over the last decade. Results reveal a superior concentration of documents on the use of imputation methods for climate time series in Asia and Europe, with notable examples from Malaysia, China, and Italy. Meanwhile, Brazil and Australia were the countries with a high number of research in America and Oceania. Moreover, temperature and precipitation were the most frequently employed climate variables. Regarding the information source, the monitoring networks were the most commonly used source for extracting data in almost all the research. On the other hand, methods such as mean techniques, simple and multiple linear regression, interpolation, and Principal Component Analysis (PCA) were the conventional statistical techniques used for imputing missing data. Furthermore, artificial neural networks demonstrated the ability to identify complex patterns in the data. Finally, Generative Adversarial Networks excel over other deep learning methods in the imputation of missing climate data.",
    "published": "2025-07-20",
    "journal": "MethodsX",
    "pmid": "",
    "paper_id": "b6ae3db32e42",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "AI-driven pharmacovigilance: Enhancing adverse drug reaction detection with deep learning and NLP.",
    "abstract": "In the healthcare industry, the ever-increasing volume of clinical trial data presents challenges for ensuring drug safety and detecting adverse drug reactions (ADRs). This study aims to address the challenge of accurately detecting Serious Adverse Events (SAEs) in pharmacovigilance, a critical component in ensuring drug safety during and after clinical trials. The key problem lies in the underreporting and delayed detection of Adverse Drug Reactions (ADRs) due to the heterogeneous nature of medical data, class imbalance, and the limited scope of traditional monitoring techniques. This study proposes a hybrid AI-driven framework that integrates structured (e.g., patient demographics, lab results) and unstructured data (e.g., clinical notes) to detect ADRs using advanced deep learning and NLP methods. The objective is to outperform traditional signal detection methods and provide interpretable predictions to aid clinicians in real-time. By leveraging advanced Machine Learning (ML) and Deep Learning (DL) techniques, including Random Forests, Gradient Boosting Machines, and Convolutional Neural Networks (CNNs), our model aims to identify potential ADRs across different patient subgroups. Through meticulous feature engineering and the application of techniques to address data imbalance, our model demonstrates improved accuracy and interpretability in predicting ADRs. The CNN model achieved an accuracy of 85 %, outperforming traditional models, such as Logistic Regression (78 %) and Support Vector Machines (80 %). These findings suggest that specific demographic and clinical factors significantly influence the likelihood of adverse reactions, offering valuable insights for targeted monitoring and risk mitigation strategies[11]. This research underscores the potential of predictive modeling to enhance pharmacovigilance efforts and ensure safer clinical trial outcomes.&#x2022;The research methodology includes a comparison of supervised learning algorithms, such as Logistic Regression, Random Forest, Gradient Boost, CNN, and genetic algorithms, to identify patterns and anomalies in clinical trial data. BERT and GPT, were also employed to provide the functionality of textual interactions over medical data.&#x2022;Performance metrics such as accuracy, precision, recall, and F1-score were systematically applied to evaluate each model's performance. Among the models tested, the CNN model with BERT achieved the highest accuracy, providing valuable insights into the potential of deep learning for enhancing pharmacovigilance practices.&#x2022;These findings suggest that an inclusion of diverse clinical data when supplied to advanced ML and NLP techniques can significantly improve the detection of ADRs, leading to better alignment with the fundamental principles of Good Clinical Practice (GCP).",
    "published": "2025-07-20",
    "journal": "MethodsX",
    "pmid": "",
    "paper_id": "45f1342606a7",
    "category": "drug_discovery"
  },
  {
    "source": "pubmed",
    "title": "Potential of ChatGPT in youth mental health emergency triage: Comparative analysis with clinicians.",
    "abstract": "",
    "published": "2025-07-19",
    "journal": "PCN reports : psychiatry and clinical neurosciences",
    "pmid": "",
    "paper_id": "14deb6b2fdbd",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Artificial intelligence-driven computational methods for antibody design and optimization.",
    "abstract": "Antibodies play a crucial role in our immune system. Their ability to bind to and neutralize pathogens opens opportunities to develop antibodies for therapeutic and diagnostic use. Computational methods capable of designing antibodies for a target antigen can revolutionize drug discovery, reducing the time and cost required for drug development. Artificial intelligence (AI) methods have recently achieved remarkable advancements in the design of protein sequences and structures, including the ability to generate scaffolds for a given motif and binders for a specific target. These generative methods have been applied to antigen-conditioned antibody design, with experimental binding confirmed for de novo-designed antibodies. This review surveys current AI methods used in antibody development, focusing on those for antigen-conditioned antibody design. The results obtained by AI-based methodologies in antibody and protein research suggest a promising direction for generating de novo binders for various target antigens.",
    "published": "2025-07-18",
    "journal": "mAbs",
    "pmid": "",
    "paper_id": "b3a7074a5df4",
    "category": "drug_discovery"
  },
  {
    "source": "pubmed",
    "title": "Ten tips to harnessing generative AI for high-quality MCQS in medical education assessment.",
    "abstract": "Generating high quality MCQs is time consuming and expensive. Many strategies are applied to produce high quality items including sharing of item banks, training of item writers and automatic item generation (AIG). Generative AI, when used with precision, has proven to reduce significantly both cost and time without compromising quality. Medical educators encounter numerous obstacles when using AI to generate MCQs of good quality. We searched the fast and recent growing medical education literature for articles related to the use of AI in generating high quality MCQs. Additionally, the development of these tips was guided by our own institutional experience. <b>&#xa0;</b>We created 10 tips for MCQ generation using AI to assist MCQ item writers in both undergraduate and graduate medical education.",
    "published": "2025-07-17",
    "journal": "Medical education online",
    "pmid": "",
    "paper_id": "020605bd5d30",
    "category": "patient_care"
  },
  {
    "source": "pubmed",
    "title": "SADA: An advanced Spectral Attention Denoising Autoencoder for high-fidelity and efficient infrared spectral data generation.",
    "abstract": "This study utilizes a Fourier transform infrared spectroscopy (FTIR)-based detection system to obtain and analyze the infrared spectra of cigarette smoke aerosols. To reduce the workload of spectral data acquisition and improve efficiency, we developed the Spectral Attention Denoising Autoencoder (SADA) model, which integrates an autoencoder (AE) architecture with a self-attention mechanism and incorporates a noise injection strategy. Compared to mainstream generative models, the SADA model performs better in generating accurate and high-fidelity spectra. To further validate the effectiveness of the generated spectra, we conducted classification experiments on hybrid datasets. By augmenting real spectral data with generated spectra, we observed significant improvements in classification accuracy across several mainstream classification models. Ablation experiments confirmed the critical roles of the self-attention mechanism and noise injection strategy in feature extraction and stable training. Additionally, the model exhibited excellent generalization capabilities across multiple public spectral datasets. The proposed SADA model not only alleviates the burden of spectral data acquisition but also provides an effective data augmentation strategy for spectral analysis tasks.",
    "published": "2025-07-16",
    "journal": "Spectrochimica acta. Part A, Molecular and biomolecular spectroscopy",
    "pmid": "",
    "paper_id": "f8860e8bbad5",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Empowering standardized residency training in China through large language models: problem analysis and solutions.",
    "abstract": "China&#x2019;s standardized residency training (SRT) is confronted with core, urgent challenges such as an uneven distribution of educational resources, a shortage of faculty, limited opportunities for practical training, subjective assessment methods, and widespread physician overwork and burnout.Large language models (LLMs) provide innovative solutions to the challenges faced by China&#x2019;s SRT by conveniently providing extensive resources, acting as virtual mentors, assisting in simulating clinical scenarios, and standardizing assessment systems.Educators must consider the integration of LLMs into SRT with caution, emphasizing their role as a complement to traditional medical education rather than a replacement, ensuring that ethical standards are prioritized and that technology serves as an aid.",
    "published": "2025-07-15",
    "journal": "Annals of medicine",
    "pmid": "",
    "paper_id": "71dec169fd6d",
    "category": "patient_care"
  },
  {
    "source": "pubmed",
    "title": "Large language models in medical education: a comparative cross-platform evaluation in answering histological questions.",
    "abstract": "Large language models (LLMs) have shown promising capabilities across medical disciplines, yet their performance in basic medical sciences remains incompletely characterized. Medical histology, requiring factual knowledge and interpretative skills, provides a unique domain for evaluating AI capabilities in medical education. To evaluate and compare the performance of five current LLMs: GPT-4.1, Claude 3.7 Sonnet, Gemini 2.0 Flash, Copilot, and DeepSeek R1 on correctly answering medical histology multiple choice questions (MCQs). This cross-sectional comparative study used 200 USMLE-style histology MCQs across 20 topics. Each LLM completed all the questions in three separate attempts. Performance metrics included accuracy rates, test-retest reliability (ICC), and topic-specific analysis. Statistical analysis employed ANOVA with post-hoc Tukey's tests and two-way mixed ANOVA for system-topic interactions. All LLMs achieved exceptionally high accuracy (Mean 91.1%, SD 7.2). Gemini performed best (92.0%), followed by Claude (91.5%), Copilot (91.0%), GPT-4 (90.8%), and DeepSeek (90.3%), with no significant differences between systems (<i>p</i>&#x2009;&gt;&#x2009;0.05). Claude showed the highest reliability (ICC&#x2009;=&#x2009;0.931), followed by GPT-4 (ICC&#x2009;=&#x2009;0.882). Complete accuracy and reproducibility (100%) were detected in Histological Methods, Blood and Hemopoiesis, and Circulatory System, while Muscle tissue (76.0%) and Lymphoid System (84.7%) presented the greatest challenges. LLMs demonstrate exceptional accuracy and reliability in answering histological MCQs, significantly outperforming other medical disciplines. Minimal inter-system variability suggests technological maturity, though topic-specific challenges and reliability concerns indicate the continued need for human expertise. These findings reflect rapid AI advancement and identify histology as particularly suitable for AI-assisted medical education.<b>Clinical trial number</b>: The clinical trial number is not pertinent to this study as it does not involve medicinal products or therapeutic interventions.",
    "published": "2025-07-12",
    "journal": "Medical education online",
    "pmid": "",
    "paper_id": "7ac40c6c4ede",
    "category": "patient_care"
  },
  {
    "source": "pubmed",
    "title": "A novel fine-tuning and evaluation methodology for large language models on IoT raw data summaries (LLM-RawDMeth): A joint perspective in diabetes care.",
    "abstract": "",
    "published": "2025-07-10",
    "journal": "Computer methods and programs in biomedicine",
    "pmid": "",
    "paper_id": "bb3619a8f71a",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Can ChatGPT accurately detect atrial fibrillation using smartwatch ECG?",
    "abstract": "",
    "published": "2025-06-27",
    "journal": "Heart &amp; lung : the journal of critical care",
    "pmid": "",
    "paper_id": "4ccff42f2c70",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Multifaceted characterization of antibacterial resin composites: A scoping review on efficacy, properties, and in vivo performance.",
    "abstract": "This scoping review aimed to collect, analyze, synthesize, and interpret the current data concerning antibacterial resin-based composites. The study followed the recommendations of the Joanna Briggs Institute and PRISMA Extension for Scoping Reviews. The searches were conducted in the PubMed, Embase, Web of Science, and Scopus databases. Studies evaluating efficacy, physical and chemical properties, cytotoxicity, and preventive effect against recurrent caries lesions provided by antibacterial resin-based composites published in the last 5 years and without language restriction were included. Fifty-three papers were analyzed. Only <i>in vitro, in situ</i>, and animal studies were published. The DMAHDM (dimethylaminohexadecyl methacrylate) was the most prevalent antibacterial agent in the resin composites and showed efficacy, did not increase cytotoxicity, nor jeopardize chemical and physical properties. The most used biofilm model and the test to evaluate the antibacterial effect was Streptococcus Mutans and the Colony Forming Unit Count. Antibacterial resin-based composites have performed exceedingly well in the large number of <i>in vitro</i> studies evaluated. However, clinical trials assessing the prevention of recurrent caries are absent and need to be further conducted to assure that using an antibacterial resin composite is a valid way to avoid restoration replacement due to recurrent caries.",
    "published": "2025-06-18",
    "journal": "The Japanese dental science review",
    "pmid": "",
    "paper_id": "0d23ec9a4c0e",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Generative artificial intelligence for general practice; new potential ahead, but are we ready?",
    "abstract": "Generative AI is expected to have a broad impact on healthcare, including general practice.Innovation is likely expected across three areas: practice support, education support, and clinical decision-making support.A coordinated effort is urgently needed to engage the international primary care academic community to draft a research agenda alongside these three areas.",
    "published": "2025-06-06",
    "journal": "The European journal of general practice",
    "pmid": "",
    "paper_id": "18b11cd18124",
    "category": "clinical_apps"
  },
  {
    "source": "pubmed",
    "title": "Leveraging large language models for preoperative prevention of cardiopulmonary bypass-associated acute kidney injury.",
    "abstract": "",
    "published": "2025-05-30",
    "journal": "Renal failure",
    "pmid": "",
    "paper_id": "b52d21d9a791",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Artificial intelligence-assisted machine learning models for predicting lung cancer survival.",
    "abstract": "",
    "published": "2025-04-10",
    "journal": "Asia-Pacific journal of oncology nursing",
    "pmid": "",
    "paper_id": "c817e02fc58d",
    "category": "foundation"
  },
  {
    "source": "pubmed",
    "title": "Comparing AI and human-generated health messages in an Arabic cultural context.",
    "abstract": "<b>Main Findings:</b> The study results show that AI-generated health messages exhibit more positive sentiment and are rated slightly lower in clarity compared to human-generated messages but are similarly rated in quality.<b>Added Knowledge:</b> The study demonstrates AI&#x2019;s potential to generate culturally sensitive messages for public communication in a highly diverse Arabic-speaking population.<b>Global Health Impact for Policy and Action:</b> The study provides evidence of the feasibility of using AI-generated content to enhance health campaigns globally, emphasizing the importance of integrating cultural and linguistic adaptability into AI-driven public health messaging.",
    "published": "2025-02-18",
    "journal": "Global health action",
    "pmid": "",
    "paper_id": "7d1d03b82f33",
    "category": "patient_care"
  }
]